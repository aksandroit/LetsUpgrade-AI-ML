{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyod\n",
      "  Downloading https://files.pythonhosted.org/packages/77/4e/5767edaccbfc227914ca774cb6ca9b628a08cbb59b9b4839296953a63d34/pyod-0.8.1.tar.gz (93kB)\n",
      "Collecting combo (from pyod)\n",
      "  Downloading https://files.pythonhosted.org/packages/0a/2a/61b6ac584e75d8df16dc27962aa5fe99d76b09da5b6710e83d4862c84001/combo-0.1.1.tar.gz\n",
      "Requirement already satisfied: joblib in e:\\akshay\\python\\lib\\site-packages (from pyod) (0.13.2)\n",
      "Requirement already satisfied: matplotlib in e:\\akshay\\python\\lib\\site-packages (from pyod) (3.1.1)\n",
      "Requirement already satisfied: numpy>=1.13 in e:\\akshay\\python\\lib\\site-packages (from pyod) (1.19.1)\n",
      "Requirement already satisfied: numba>=0.35 in e:\\akshay\\python\\lib\\site-packages (from pyod) (0.45.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in e:\\akshay\\python\\lib\\site-packages (from pyod) (1.4.1)\n",
      "Requirement already satisfied: scikit_learn>=0.19.1 in e:\\akshay\\python\\lib\\site-packages (from pyod) (0.23.2)\n",
      "Requirement already satisfied: six in e:\\akshay\\python\\lib\\site-packages (from pyod) (1.12.0)\n",
      "Collecting suod (from pyod)\n",
      "  Downloading https://files.pythonhosted.org/packages/a1/87/9170cabe1b5e10a7d095c0e28f2e30e7c1886a13f063de85d3cfacc06f4b/suod-0.0.4.tar.gz (2.1MB)\n",
      "Requirement already satisfied: cycler>=0.10 in e:\\akshay\\python\\lib\\site-packages (from matplotlib->pyod) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in e:\\akshay\\python\\lib\\site-packages (from matplotlib->pyod) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in e:\\akshay\\python\\lib\\site-packages (from matplotlib->pyod) (2.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in e:\\akshay\\python\\lib\\site-packages (from matplotlib->pyod) (2.8.0)\n",
      "Requirement already satisfied: llvmlite>=0.29.0dev0 in e:\\akshay\\python\\lib\\site-packages (from numba>=0.35->pyod) (0.29.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in e:\\akshay\\python\\lib\\site-packages (from scikit_learn>=0.19.1->pyod) (2.1.0)\n",
      "Requirement already satisfied: setuptools in e:\\akshay\\python\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib->pyod) (41.4.0)\n",
      "Building wheels for collected packages: pyod, combo, suod\n",
      "  Building wheel for pyod (setup.py): started\n",
      "  Building wheel for pyod (setup.py): finished with status 'done'\n",
      "  Created wheel for pyod: filename=pyod-0.8.1-cp37-none-any.whl size=105657 sha256=7de515dc5675f072837a1c32138b9ef70d6965876c95bb3636737bf730701c55\n",
      "  Stored in directory: C:\\Users\\HP\\AppData\\Local\\pip\\Cache\\wheels\\2e\\ca\\18\\727e9d98a41f5f4385a97d5b429f3a9c8fbee13f9780c18642\n",
      "  Building wheel for combo (setup.py): started\n",
      "  Building wheel for combo (setup.py): finished with status 'done'\n",
      "  Created wheel for combo: filename=combo-0.1.1-cp37-none-any.whl size=42121 sha256=75481e2fc225c4b8ddbf6275439dfb899f5f98b48cc18d4e268e22f855d8c26b\n",
      "  Stored in directory: C:\\Users\\HP\\AppData\\Local\\pip\\Cache\\wheels\\55\\ec\\e5\\a2331372c676c467e70c6646e646edf6997d5c4905b8c0f5e6\n",
      "  Building wheel for suod (setup.py): started\n",
      "  Building wheel for suod (setup.py): finished with status 'done'\n",
      "  Created wheel for suod: filename=suod-0.0.4-cp37-none-any.whl size=2167164 sha256=cb0ead0f6e8e9e9e3218eef7e9628027ccf6a5da3f4cb92d74f1b9ad2a3ec468\n",
      "  Stored in directory: C:\\Users\\HP\\AppData\\Local\\pip\\Cache\\wheels\\57\\55\\e5\\a4fca65bba231f6d0115059b589148774b41faea25b3f2aa27\n",
      "Successfully built pyod combo suod\n",
      "Installing collected packages: combo, suod, pyod\n",
      "Successfully installed combo-0.1.1 pyod-0.8.1 suod-0.0.4\n"
     ]
    }
   ],
   "source": [
    "!pip install pyod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\AKSHAY\\python\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'FeatureBagiing' from 'pyod.models.feature_bagging' (E:\\AKSHAY\\python\\lib\\site-packages\\pyod\\models\\feature_bagging.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-28c38ee93734>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabod\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mABOD\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miforest\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mIForest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpyod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_bagging\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFeatureBagiing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'FeatureBagiing' from 'pyod.models.feature_bagging' (E:\\AKSHAY\\python\\lib\\site-packages\\pyod\\models\\feature_bagging.py)"
     ]
    }
   ],
   "source": [
    "from pyod.models.pca import PCA\n",
    "from pyod.models.mcd import MCD\n",
    "from pyod.models.ocsvm import OCSVM\n",
    "from pyod.models.lof import LOF\n",
    "from pyod.models.cblof import CBLOF\n",
    "from pyod.models.knn import KNN\n",
    "from pyod.models.hbos import HBOS\n",
    "from pyod.models.abod import ABOD\n",
    "from pyod.models.iforest import IForest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.models.feature_bagging import FeatureBagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.utils.utility import standardizer\n",
    "from pyod.utils.utility import precision_n_scores\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_file_list = ['arrhythmia.mat',\n",
    "                'cardio.mat',\n",
    "                'glass.mat',\n",
    "                \"ionosphere.mat\",\n",
    "                \"letter.mat\",\n",
    "                \"lympho.mat\",\n",
    "                \"mnist.mat\",\n",
    "                \"musk.mat\", \n",
    "                \"optdigits.mat\",\n",
    "                \"pendigits.mat\",\n",
    "                \"pima.mat\",\n",
    "                \"satellite.mat\",\n",
    "                \"satimage-2.mat\",\n",
    "                \"shuttle.mat\",\n",
    "                \"vertebral.mat\",\n",
    "                \"vowels.mat\",\n",
    "                \"wbc.mat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__header__': b'MATLAB 5.0 MAT-file, written by Octave 3.8.0, 2014-12-18 10:48:09 UTC',\n",
       " '__version__': '1.0',\n",
       " '__globals__': [],\n",
       " 'X': array([[ 0.00491231,  0.69319077, -0.20364049, ...,  0.23149795,\n",
       "         -0.28978574, -0.49329397],\n",
       "        [ 0.11072935, -0.07990259, -0.20364049, ...,  0.09356344,\n",
       "         -0.25638541, -0.49329397],\n",
       "        [ 0.21654639, -0.27244466, -0.20364049, ...,  0.02459619,\n",
       "         -0.25638541,  1.14001753],\n",
       "        ...,\n",
       "        [-0.41835583, -0.91998844, -0.16463485, ..., -1.49268341,\n",
       "          0.24461959, -0.49329397],\n",
       "        [-0.41835583, -0.91998844, -0.15093411, ..., -1.42371616,\n",
       "          0.14441859, -0.49329397],\n",
       "        [-0.41835583, -0.91998844, -0.20364049, ..., -1.28578165,\n",
       "          3.58465295, -0.49329397]]),\n",
       " 'y': array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading the MAT file.\n",
    "\n",
    "data=loadmat(\"C:/Users/HP/LetsUpgrade/Project -1/cardio.mat\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, (1831, 21))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reshaping :\n",
    "\n",
    "type(data['X']),data['X'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, (1831, 1))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshaping for DV\n",
    "type(data['y']), data['y'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Could not find a version that satisfies the requirement time (from versions: none)\n",
      "ERROR: No matching distribution found for time\n"
     ]
    }
   ],
   "source": [
    "!pip install time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exploring files\n",
    "\n",
    "from time import time\n",
    "random_state = np.random.RandomState(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".. Processing arrhythmia.mat ...\n",
      "\n",
      ".. Processing cardio.mat ...\n",
      "\n",
      ".. Processing glass.mat ...\n",
      "\n",
      ".. Processing ionosphere.mat ...\n",
      "\n",
      ".. Processing letter.mat ...\n",
      "\n",
      ".. Processing lympho.mat ...\n",
      "\n",
      ".. Processing mnist.mat ...\n",
      "\n",
      ".. Processing musk.mat ...\n",
      "\n",
      ".. Processing optdigits.mat ...\n",
      "\n",
      ".. Processing pendigits.mat ...\n",
      "\n",
      ".. Processing pima.mat ...\n",
      "\n",
      ".. Processing satellite.mat ...\n",
      "\n",
      ".. Processing satimage-2.mat ...\n",
      "\n",
      ".. Processing shuttle.mat ...\n",
      "\n",
      ".. Processing vertebral.mat ...\n",
      "\n",
      ".. Processing vowels.mat ...\n",
      "\n",
      ".. Processing wbc.mat ...\n"
     ]
    }
   ],
   "source": [
    "for mat_file in mat_file_list:\n",
    "    print(\"\\n.. Processing\", mat_file, '...')\n",
    "    mat=loadmat(\"C:/Users/HP/LetsUpgrade/Project -1/arrhythmia.mat\")\n",
    "    mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mat['X']\n",
    "y = mat['y'].ravel()\n",
    "outliners_fraction = np.count_nonzero(y) / len(y)\n",
    "outliers_percentage = round(outliners_fraction*100, ndigits=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14601769911504425"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outliners_fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct containers for saving results\n",
    "\n",
    "roc_list = [mat_file[:-4], X.shape[0], X.shape[1], outliers_percentage]\n",
    "prn_list = [mat_file[:-4], X.shape[0], X.shape[1], outliers_percentage]\n",
    "time_list = [mat_file[:-4], X.shape[0], X.shape[1], outliers_percentage]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wbc', 452, 274, 14.6018]\n",
      "['wbc', 452, 274, 14.6018]\n",
      "['wbc', 452, 274, 14.6018]\n"
     ]
    }
   ],
   "source": [
    "print(roc_list)\n",
    "print(prn_list)\n",
    "print(time_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.4,\n",
    "                                                    random_state=random_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 59.    1.  155.  ...  -1.2  14.    0.4]\n",
      " [ 26.    0.  180.  ...  -1.   16.8   7.4]\n",
      " [ 68.    0.  164.  ...   2.7  18.8  41.4]\n",
      " ...\n",
      " [ 34.    1.  165.  ...   0.8   1.9   8.1]\n",
      " [ 39.    1.  164.  ...   1.3  24.1  33.7]\n",
      " [ 19.    1.  157.  ...   1.3   9.4  17.9]]\n",
      "[[ 51.    0.  170.  ...   2.6  23.7  47.6]\n",
      " [ 45.    0.  175.  ...   1.   10.5  17.9]\n",
      " [ 31.    1.  165.  ...   0.9   9.6  14.4]\n",
      " ...\n",
      " [ 56.    0.  170.  ...   1.   24.   32.2]\n",
      " [ 50.    0.  172.  ...   1.6  14.2  27.6]\n",
      " [ 51.    1.  160.  ...   1.5  12.   24. ]]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1\n",
      " 0 1 0 0 0 1 0 0 0 1 0 0]\n",
      "[0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 1 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)\n",
    "print(X_test)\n",
    "print(y_train)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.79514353  0.9321832  -0.36920653 ... -1.61666889 -0.41511185\n",
      "  -1.60714874]\n",
      " [-1.25412696 -1.07275051  0.50113941 ... -1.48155177 -0.21381656\n",
      "  -1.22257319]\n",
      " [ 1.35403549 -1.07275051 -0.05588199 ...  1.018115   -0.07003421\n",
      "   0.64536522]\n",
      " ...\n",
      " [-0.75733411  0.9321832  -0.02106815 ... -0.26549767 -1.28499508\n",
      "  -1.18411563]\n",
      " [-0.44683858  0.9321832  -0.05588199 ...  0.07229514  0.31098902\n",
      "   0.22233211]\n",
      " [-1.6888207   0.9321832  -0.29957885 ...  0.07229514 -0.74581126\n",
      "  -0.64570986]]\n",
      "[[ 0.29835069 -1.07275051  0.15300104 ...  0.95055643  0.28223255\n",
      "   0.98598928]\n",
      " [-0.07424395 -1.07275051  0.32707022 ... -0.13038054 -0.66673097\n",
      "  -0.64570986]\n",
      " [-0.94363143  0.9321832  -0.02106815 ... -0.19793911 -0.73143302\n",
      "  -0.83799763]\n",
      " ...\n",
      " [ 0.60884622 -1.07275051  0.15300104 ... -0.13038054  0.30379991\n",
      "   0.13992306]\n",
      " [ 0.23625158 -1.07275051  0.22262871 ...  0.27497082 -0.40073362\n",
      "  -0.11279802]\n",
      " [ 0.29835069  0.9321832  -0.19513734 ...  0.20741226 -0.5588942\n",
      "  -0.31057973]]\n"
     ]
    }
   ],
   "source": [
    "#standardizing data for processing:\n",
    "X_train_norm, X_test_norm = standardizer(X_train, X_test)\n",
    "print(X_train_norm)\n",
    "print(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-50-df3184157604>, line 29)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-50-df3184157604>\"\u001b[1;36m, line \u001b[1;32m29\u001b[0m\n\u001b[1;33m    clf_name = clf_name, roc=roc, prn = prn), duration = duration))\u001b[0m\n\u001b[1;37m                                                                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "classifiers = {\"Angel-based Outlier Detector (ABOD)\" : ABOD(\n",
    "               contamination = outliers_fraction, check_estimator = False, \n",
    "                random_state = random_state),\n",
    "              'Feature Bagging' : FeatureBagging(contamination = outliers_fraction,\n",
    "                                                random_state=random_state),\n",
    "              \"Histogram-base Outlier Detection (HBOS)\": HBOS(\n",
    "                   contamination = outliers_fraction),\n",
    "              \"Isolation Forest\": IForest(contamination= outliers_fraction,\n",
    "                                         random_state= random_state),\n",
    "              \"K Nearest Neighbors (KNN)\" : KNN(contamination = outliers_fraction),\n",
    "              'Local Outlier Factor (LOF)' : LOF(\n",
    "                contamination= outliers_fraction),\n",
    "              \"Minimum Covariance Determinat (MCD)\": MCD(\n",
    "                contamination=outliers_fraction, random_state=random_state),\n",
    "              }\n",
    "for clf_name, clf in classifiers.items():\n",
    "    t0 = time()\n",
    "    clf.fit(X_train_norm)\n",
    "    test_scores= clf.decision_function(X_test_norm)\n",
    "    t1 = time()\n",
    "    duration = round(t1 - t0, ndigits =4)\n",
    "    time_list.append(duration)\n",
    "    \n",
    "    roc = round(roc_auc_score(y_test, test_scores), ndigits =4)\n",
    "    prn = round(precision_n_scores(y_test, test_scores), ndigits=4)\n",
    "    \n",
    "    print('{clf_name} ROC: (roc), precision @ rank n: {prn},'\n",
    "         'execution time: {duration}s'.format(\n",
    "         clf_name = clf_name, roc=roc, prn = prn), duration = duration))\n",
    "    \n",
    "        roc_list.appead(roc)\n",
    "        prn_list.append(prn)\n",
    "    \n",
    "    temp_df = pd.DataFrame (time_list).transpose()\n",
    "    temp_df.columns = df_columns\n",
    "    time_df =pd.concat([roc_df, temp_df], axis=0)\n",
    "    \n",
    "    temp_df = pd.DataFrame (prn_list).transpose()\n",
    "    temp_df.columns = df_columns\n",
    "    time_df =pd.concat([prn_df, temp_df], axis=0)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
